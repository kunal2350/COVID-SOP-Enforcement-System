{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "from scipy.spatial import distance as distance\n",
    "import cmath\n",
    "import imutils\n",
    "import base64\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in d:\\anaconda3\\envs\\eyeblinkpassword\\lib\\site-packages (4.5.1.48)\n",
      "Requirement already satisfied: numpy>=1.13.3 in d:\\anaconda3\\envs\\eyeblinkpassword\\lib\\site-packages (from opencv-python) (1.15.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in d:\\anaconda3\\envs\\eyeblinkpassword\\lib\\site-packages (0.5.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'person'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelpath='darknet/data/coco.names'\n",
    "file=open(labelpath)\n",
    "label=file.read().strip().split(\"\\n\")\n",
    "label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightspath=r'C:\\Users\\kunal\\Desktop\\Crowd-Detection-using-openCV\\darknet\\cfg\\yolov3.weights'\n",
    "configpath=r'C:\\Users\\kunal\\Desktop\\Crowd-Detection-using-openCV\\darknet\\cfg\\yolov3.cfg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=cv2.dnn.readNetFromDarknet(configpath,weightspath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "videopath=r'C:\\Users\\kunal\\Desktop\\Crowd-Detection-using-openCV\\video\\run.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln=net.getLayerNames()\n",
    "ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_EDUCATIONAL = \"http://things.ubidots.com\"\n",
    "URL_INDUSTRIAL = \"http://industrial.api.ubidots.com\"\n",
    "INDUSTRIAL_USER = True  # Set this to False if you are an educational user\n",
    "TOKEN = \"BBFF-O8HEzPno59vPntQQJHq33AIhPk5Jlk\"  # Put here your Ubidots TOKEN\n",
    "DEVICE = \"detector\"  # Device where will be stored the result\n",
    "VARIABLE = \"people\"  # Variable where will be stored the result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def buildPayload(variable, value):\\n    return {variable: {\"value\": value}}'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def buildPayload(variable, value):\n",
    "    return {variable: {\"value\": value}}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildPayload(variable, value, context):\n",
    "    return {variable: {\"value\": value, \"context\": context}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_base64(image):\n",
    "    image = imutils.resize(image, width=300)\n",
    "    img_str = cv2.imencode('.png', image)[1].tostring()\n",
    "    b64 = base64.b64encode(img_str)\n",
    "\n",
    "    return b64.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sendToUbidots(token, device, variable, value, context={}, industrial=True):\n",
    "    # Builds the endpoint\n",
    "    url = URL_INDUSTRIAL if industrial else URL_EDUCATIONAL\n",
    "    url = \"{}/api/v1.6/devices/{}\".format(url, device)\n",
    "\n",
    "    payload = buildPayload(variable, value,context)\n",
    "    headers = {\"X-Auth-Token\": token, \"Content-Type\": \"application/json\"}\n",
    "\n",
    "    attempts = 0\n",
    "    status = 400\n",
    "   \n",
    "    while status >= 400 and attempts <= 5:\n",
    "        req = requests.post(url=url, headers=headers, json=payload)\n",
    "        status = req.status_code\n",
    "        attempts += 1\n",
    "        time.sleep(1)\n",
    "        print(req)\n",
    "\n",
    "    return req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Sending actual frame results\n",
      "<Response [200]>\n",
      "[INFO] Sending actual frame results\n",
      "<Response [200]>\n",
      "[INFO] Sending actual frame results\n",
      "<Response [200]>\n",
      "[INFO] Sending actual frame results\n",
      "<Response [200]>\n",
      "[INFO] Sending actual frame results\n",
      "<Response [200]>\n",
      "[INFO] Sending actual frame results\n",
      "<Response [200]>\n",
      "[INFO] Sending actual frame results\n",
      "<Response [200]>\n",
      "[INFO] Sending actual frame results\n",
      "<Response [200]>\n",
      "[INFO] Sending actual frame results\n",
      "<Response [200]>\n",
      "[INFO] Sending actual frame results\n",
      "<Response [200]>\n",
      "[INFO] Sending actual frame results\n",
      "<Response [200]>\n",
      "[INFO] Sending actual frame results\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "video=cv2.VideoCapture(videopath)\n",
    "ret = video\n",
    "init=time.time()\n",
    "sample_time=5\n",
    "if sample_time < 1:\n",
    "        sample_time = 1\n",
    "while(True):\n",
    "    \n",
    "    \n",
    "    ret,frame=video.read()\n",
    "    if ret==False:\n",
    "        print('Error running the file :(')\n",
    "    frame=cv2.resize(frame, (640,440), interpolation =cv2.INTER_AREA)\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "    r = blob[0, 0, :, :]\n",
    "    net.setInput(blob)\n",
    "    t0 = time.time()\n",
    "    outputs = net.forward(ln)\n",
    "    t = time.time()\n",
    "\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    classIDs = []\n",
    "    center=[]\n",
    "    output=[]\n",
    "    count=0\n",
    "    results=[]\n",
    "    breach=set()\n",
    "    \n",
    "    h, w = frame.shape[:2]\n",
    "    for output in outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "           \n",
    "            confidence = scores[classID]\n",
    "           \n",
    "            if confidence > 0.5:\n",
    "                box = detection[0:4] * np.array([w, h, w, h])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "                center.append((centerX,centerY))\n",
    "                box = [x, y, int(width), int(height)]\n",
    "                boxes.append(box)\n",
    "                confidences.append(float(confidence))\n",
    "                classIDs.append(classID)\n",
    "\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    \n",
    "    if len(indices) > 0:\n",
    "        for i in indices.flatten():\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "            #color = [int(c) for c in colors[classIDs[i]]]\n",
    "            if(label[classIDs[i]]=='person'):\n",
    "                #people()\n",
    "                cX=(int)(x+(y/2))\n",
    "                cY=(int)(w+(h/2))\n",
    "                center.append((cX,cY))\n",
    "                res=((x,y,x+w,y+h),center[i])\n",
    "                results.append(res) \n",
    "                dist=cmath.sqrt(((center[i][0]-center[i+1][0])**2)+((center[i][1]-center[i+1][1])**2))\n",
    "                if(dist.real <100):\n",
    "                    cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255), 2)\n",
    "                    cv2.circle(frame,center[i],4,(0,0,255),-1)\n",
    "                    #cv2.line(frame, (center[i][0], center[i][1]), (center[i+1][0], center[i+1][1]), (0,0, 255), thickness=3, lineType=8)\n",
    "                    count=count+1\n",
    "                    \n",
    "                else:\n",
    "                    cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0), 2)\n",
    "                    cv2.circle(frame,center[i],4,(0,255,0),-1)\n",
    "        #cv2.rectangle(frame,(startX, startY), (endX, endY),color, 2)\n",
    "        #cv2.circle(frame,(cX,cY),4,color,-1)\n",
    "        cv2.putText(frame,\"Violation: {}\".format(count), (20, frame.shape[0] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (23,255,255), 1) \n",
    "        if time.time() - init >=sample_time:\n",
    "            print(\"[INFO] Sending actual frame results\")\n",
    "            # Converts the image to base 64 and adds it to the context\n",
    "            b64 = convert_to_base64(frame)\n",
    "            context = {\"image\": b64}\n",
    "            sendToUbidots(TOKEN, DEVICE,VARIABLE,count,context=context)\n",
    "            init = time.time()\n",
    "       \n",
    "\n",
    "        \n",
    "                    \n",
    "    \n",
    "    #cv2.putText(frame,\"Violation: {}\".format(count), (20, frame.shape[0] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (23,255,255), 1)      \n",
    "\n",
    "    #frame_blob=makeblob(frame)\n",
    "    cv2.imshow('Frame',frame)\n",
    "    #cv2.VideoWriter(r'C:\\Users\\Lenovo\\Desktop\\Crowd Detection\\video\\walk2.mp4', cv2.VideoWriter_fourcc(*'MJPG'), 10, (640,440)).write(frame) \n",
    "    \n",
    "    if(cv2.waitKey(1)==ord('q')):\n",
    "        break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
